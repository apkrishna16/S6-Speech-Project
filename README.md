# S6-Speech-Project
This project focuses on developing an advanced emotion recognition system using speech data to enhance human-computer interaction. Utilizing datasets such as RAVDESS, CREMA-D, TESS, and SAVEE, the study involved preprocessing steps like noise reduction and normalization, along with feature extraction techniques including MFCC and Mel spectrogram. A Convolutional Neural Network (CNN) was employed for classification, achieving high accuracy and demonstrating the potential of deep learning in recognizing emotional nuances in speech. This project sets a foundation for future research in integrating multimodal data for improved emotion recognition systems.
